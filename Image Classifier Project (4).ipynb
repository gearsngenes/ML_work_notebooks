{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Developing an AI application\n",
    "\n",
    "Going forward, AI algorithms will be incorporated into more and more everyday applications. For example, you might want to include an image classifier in a smart phone app. To do this, you'd use a deep learning model trained on hundreds of thousands of images as part of the overall application architecture. A large part of software development in the future will be using these types of models as common parts of applications. \n",
    "\n",
    "In this project, you'll train an image classifier to recognize different species of flowers. You can imagine using something like this in a phone app that tells you the name of the flower your camera is looking at. In practice you'd train this classifier, then export it for use in your application. We'll be using [this dataset](http://www.robots.ox.ac.uk/~vgg/data/flowers/102/index.html) of 102 flower categories, you can see a few examples below. \n",
    "\n",
    "<img src='assets/Flowers.png' width=500px>\n",
    "\n",
    "The project is broken down into multiple steps:\n",
    "\n",
    "* Load and preprocess the image dataset\n",
    "* Train the image classifier on your dataset\n",
    "* Use the trained classifier to predict image content\n",
    "\n",
    "We'll lead you through each part which you'll implement in Python.\n",
    "\n",
    "When you've completed this project, you'll have an application that can be trained on any set of labeled images. Here your network will be learning about flowers and end up as a command line application. But, what you do with your new skills depends on your imagination and effort in building a dataset. For example, imagine an app where you take a picture of a car, it tells you what the make and model is, then looks up information about it. Go build your own dataset and make something new.\n",
    "\n",
    "First up is importing the packages you'll need. It's good practice to keep all the imports at the beginning of your code. As you work through this notebook and find you need to import a package, make sure to add the import up here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports here\n",
    "import torch\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.transforms import functional as TF\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "Here you'll use `torchvision` to load the data ([documentation](http://pytorch.org/docs/0.3.0/torchvision/index.html)). The data should be included alongside this notebook, otherwise you can [download it here](https://s3.amazonaws.com/content.udacity-data.com/nd089/flower_data.tar.gz). The dataset is split into three parts, training, validation, and testing. For the training, you'll want to apply transformations such as random scaling, cropping, and flipping. This will help the network generalize leading to better performance. You'll also need to make sure the input data is resized to 224x224 pixels as required by the pre-trained networks.\n",
    "\n",
    "The validation and testing sets are used to measure the model's performance on data it hasn't seen yet. For this you don't want any scaling or rotation transformations, but you'll need to resize then crop the images to the appropriate size.\n",
    "\n",
    "The pre-trained networks you'll use were trained on the ImageNet dataset where each color channel was normalized separately. For all three sets you'll need to normalize the means and standard deviations of the images to what the network expects. For the means, it's `[0.485, 0.456, 0.406]` and for the standard deviations `[0.229, 0.224, 0.225]`, calculated from the ImageNet images.  These values will shift each color channel to be centered at 0 and range from -1 to 1.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'flowers'\n",
    "train_dir = data_dir + '/train'\n",
    "valid_dir = data_dir + '/valid'\n",
    "test_dir = data_dir + '/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define your transforms for the training, validation, and testing sets\n",
    "train_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                transforms.CenterCrop(224),\n",
    "                                transforms.RandomHorizontalFlip(),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.485, 0.485, 0.485), (0.229, 0.224, 0.225))])\n",
    "valid_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "testing_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "# TODO: Load the datasets with ImageFolder\n",
    "train_data = datasets.ImageFolder(train_dir, transform=train_transforms)\n",
    "valid_data = datasets.ImageFolder(train_dir, transform=valid_transforms)\n",
    "test_data = datasets.ImageFolder(train_dir, transform=testing_transforms)\n",
    "\n",
    "# TODO: Using the image datasets and the trainforms, define the dataloaders\n",
    "train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=24, shuffle=True)\n",
    "valid_dataloader = torch.utils.data.DataLoader(valid_data, batch_size=24, shuffle=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=24, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label mapping\n",
    "\n",
    "You'll also need to load in a mapping from category label to category name. You can find this in the file `cat_to_name.json`. It's a JSON object which you can read in with the [`json` module](https://docs.python.org/2/library/json.html). This will give you a dictionary mapping the integer encoded categories to the actual names of the flowers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'21': 'fire lily', '3': 'canterbury bells', '45': 'bolero deep blue', '1': 'pink primrose', '34': 'mexican aster', '27': 'prince of wales feathers', '7': 'moon orchid', '16': 'globe-flower', '25': 'grape hyacinth', '26': 'corn poppy', '79': 'toad lily', '39': 'siam tulip', '24': 'red ginger', '67': 'spring crocus', '35': 'alpine sea holly', '32': 'garden phlox', '10': 'globe thistle', '6': 'tiger lily', '93': 'ball moss', '33': 'love in the mist', '9': 'monkshood', '102': 'blackberry lily', '14': 'spear thistle', '19': 'balloon flower', '100': 'blanket flower', '13': 'king protea', '49': 'oxeye daisy', '15': 'yellow iris', '61': 'cautleya spicata', '31': 'carnation', '64': 'silverbush', '68': 'bearded iris', '63': 'black-eyed susan', '69': 'windflower', '62': 'japanese anemone', '20': 'giant white arum lily', '38': 'great masterwort', '4': 'sweet pea', '86': 'tree mallow', '101': 'trumpet creeper', '42': 'daffodil', '22': 'pincushion flower', '2': 'hard-leaved pocket orchid', '54': 'sunflower', '66': 'osteospermum', '70': 'tree poppy', '85': 'desert-rose', '99': 'bromelia', '87': 'magnolia', '5': 'english marigold', '92': 'bee balm', '28': 'stemless gentian', '97': 'mallow', '57': 'gaura', '40': 'lenten rose', '47': 'marigold', '59': 'orange dahlia', '48': 'buttercup', '55': 'pelargonium', '36': 'ruby-lipped cattleya', '91': 'hippeastrum', '29': 'artichoke', '71': 'gazania', '90': 'canna lily', '18': 'peruvian lily', '98': 'mexican petunia', '8': 'bird of paradise', '30': 'sweet william', '17': 'purple coneflower', '52': 'wild pansy', '84': 'columbine', '12': \"colt's foot\", '11': 'snapdragon', '96': 'camellia', '23': 'fritillary', '50': 'common dandelion', '44': 'poinsettia', '53': 'primula', '72': 'azalea', '65': 'californian poppy', '80': 'anthurium', '76': 'morning glory', '37': 'cape flower', '56': 'bishop of llandaff', '60': 'pink-yellow dahlia', '82': 'clematis', '58': 'geranium', '75': 'thorn apple', '41': 'barbeton daisy', '95': 'bougainvillea', '43': 'sword lily', '83': 'hibiscus', '78': 'lotus lotus', '88': 'cyclamen', '94': 'foxglove', '81': 'frangipani', '74': 'rose', '89': 'watercress', '73': 'water lily', '46': 'wallflower', '77': 'passion flower', '51': 'petunia'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('cat_to_name.json', 'r') as f:\n",
    "    cat_to_name = json.load(f)\n",
    "print(cat_to_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building and training the classifier\n",
    "\n",
    "Now that the data is ready, it's time to build and train the classifier. As usual, you should use one of the pretrained models from `torchvision.models` to get the image features. Build and train a new feed-forward classifier using those features.\n",
    "\n",
    "We're going to leave this part up to you. Refer to [the rubric](https://review.udacity.com/#!/rubrics/1663/view) for guidance on successfully completing this section. Things you'll need to do:\n",
    "\n",
    "* Load a [pre-trained network](http://pytorch.org/docs/master/torchvision/models.html) (If you need a starting point, the VGG networks work great and are straightforward to use)\n",
    "* Define a new, untrained feed-forward network as a classifier, using ReLU activations and dropout\n",
    "* Train the classifier layers using backpropagation using the pre-trained network to get the features\n",
    "* Track the loss and accuracy on the validation set to determine the best hyperparameters\n",
    "\n",
    "We've left a cell open for you below, but use as many as you need. Our advice is to break the problem up into smaller parts you can run separately. Check that each part is doing what you expect, then move on to the next. You'll likely find that as you work through each part, you'll need to go back and modify your previous code. This is totally normal!\n",
    "\n",
    "When training make sure you're updating only the weights of the feed-forward network. You should be able to get the validation accuracy above 70% if you build everything right. Make sure to try different hyperparameters (learning rate, units in the classifier, epochs, etc) to find the best model. Save those hyperparameters to use as default values in the next part of the project.\n",
    "\n",
    "One last important tip if you're using the workspace to run your code: To avoid having your workspace disconnect during the long-running tasks in this notebook, please read in the earlier page in this lesson called Intro to\n",
    "GPU Workspaces about Keeping Your Session Active. You'll want to include code from the workspace_utils.py module.\n",
    "\n",
    "**Note for Workspace users:** If your network is over 1 GB when saved as a checkpoint, there might be issues with saving backups in your workspace. Typically this happens with wide dense layers after the convolutional layers. If your saved checkpoint is larger than 1 GB (you can open a terminal and check with `ls -lh`), you should reduce the size of your hidden layers and train again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg11-bbd30ac9.pth\" to /root/.torch/models/vgg11-bbd30ac9.pth\n",
      "100%|██████████| 531456000/531456000 [00:05<00:00, 89528334.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU(inplace)\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace)\n",
      "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace)\n",
      "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (12): ReLU(inplace)\n",
      "    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (14): ReLU(inplace)\n",
      "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (17): ReLU(inplace)\n",
      "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (19): ReLU(inplace)\n",
      "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=2048, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2)\n",
      "    (3): Linear(in_features=2048, out_features=512, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.2)\n",
      "    (6): Linear(in_features=512, out_features=102, bias=True)\n",
      "    (7): LogSoftmax()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# TODO: Build and train your network\n",
    "#Get the pre-trained neural network\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = models.vgg11(pretrained=True)\n",
    "\n",
    "\n",
    "\n",
    "# Freeze parameters so we don't backprop through them\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.classifier = nn.Sequential(nn.Linear(25088, 2048),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(0.2),\n",
    "                                 nn.Linear(2048, 512),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(0.2),\n",
    "                                 nn.Linear(512, 102),\n",
    "                                 nn.LogSoftmax(dim=1))\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Only train the classifier parameters, feature parameters are frozen\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=0.003)\n",
    "\n",
    "model.to(device);\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0      Loss:  tensor(4.6026, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(17.8659, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(17.7646, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(12.4208, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(6.6374, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(4.5591, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(4.4246, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(4.4839, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(4.8677, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(4.2496, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(4.5126, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(4.2149, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(4.3179, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(4.1290, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(4.2300, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.6474, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(4.1276, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(4.7939, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(4.0009, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(4.3516, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.9147, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.8698, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(4.0915, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(4.0959, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.8678, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(4.0874, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.6766, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.4631, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(4.5750, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.2622, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.7178, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(4.0853, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.9918, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(4.1805, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.8300, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.3174, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.8862, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(4.1229, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.8380, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.7962, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.2979, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.0890, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.1321, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.5843, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.8759, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.8712, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.7388, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.5916, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.0708, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.2539, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.1865, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.9860, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.4032, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.1759, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.0042, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.7162, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(4.3299, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.2352, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.0126, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.0478, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.6385, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.9986, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.6808, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.2776, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.3906, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.4636, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.4105, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.9314, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.0730, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.4103, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.7747, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.9069, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.3444, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.8390, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.3800, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.2415, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.3781, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.1606, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.3510, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.8070, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.2710, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.0935, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.5094, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.4917, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.0421, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.2490, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.0540, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.5590, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.7712, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.9124, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.0424, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.7448, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.5203, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.7564, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.4371, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.9027, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.8547, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.3379, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.0663, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.9955, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.8990, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.3694, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.5356, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.0869, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.4984, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.9025, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.1085, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.3719, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.2762, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.1149, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.6594, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.2408, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.7171, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.3144, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.9055, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.8144, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.4629, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.8472, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.0448, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(4.3365, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.4150, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.8194, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.9999, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.1773, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.9819, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.9847, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.6469, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.6435, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.9981, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.1994, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.7915, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(4.0735, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.0563, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.6894, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.8107, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.2694, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.7914, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.4844, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.1364, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.0962, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.8798, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.9590, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.7269, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.6109, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(4.1812, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.8009, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.0777, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.8330, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.0413, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.2857, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.6291, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.0957, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.1212, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.4953, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.6250, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.4279, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.1792, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.9683, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.4885, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.6669, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.1593, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.4419, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.1778, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.3718, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.9835, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.2439, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.9591, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.0263, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.6394, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.5860, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.1900, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.0248, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.5976, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.3201, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.1399, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.1436, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.6678, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.8544, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.1018, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.9040, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.4484, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.0537, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.2830, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.5997, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.8501, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.7402, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.1647, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.5437, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.9084, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.4833, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.9187, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.2894, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.4497, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.9978, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.0824, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.6641, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.1914, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.5908, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.0812, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.7930, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.4144, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.9308, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.8105, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.1444, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.2383, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.8297, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.8930, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.9858, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.7658, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.7083, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.5464, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.6665, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.9633, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.3364, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.4849, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.0600, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.6455, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.0375, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.7768, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.7388, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.6227, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.2706, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.7541, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.0823, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.7884, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.6107, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.3595, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.6147, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.0205, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.2387, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.8115, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(4.4916, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.2342, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.6302, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.7887, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.6432, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.4750, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.9581, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.8087, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.9537, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.0545, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.7956, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.8963, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.2879, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.8452, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.3667, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.6844, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.5980, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.0274, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.6851, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.8682, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.8582, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.8163, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.0039, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.4900, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.9521, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.6299, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.8334, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.4731, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.8197, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.5384, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.9610, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.5203, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.3975, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.8924, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.4366, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.8985, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.5082, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.5320, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.4427, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.4567, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.6568, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.0432, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(3.2395, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.5000, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.5161, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.0336, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.0079, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.0058, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.6184, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.7372, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.1886, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.5339, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.5564, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.1625, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.7067, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.3601, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(4.0976, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.0365, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.8566, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.0713, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.4942, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.6437, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.5377, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.4612, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.5496, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.5798, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.5798, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.0178, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.4232, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.0943, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(3.6757, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.9898, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.4317, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.9175, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.5404, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.2306, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.5160, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.4350, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.1300, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(4.5443, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.1575, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.4195, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.1022, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.8241, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.3506, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.9882, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.1795, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.4477, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.8244, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(3.0209, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.7688, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.0481, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.4886, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.7990, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.5529, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.4707, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.0283, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.4817, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.6166, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.4167, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.6052, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.8426, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.8683, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.0030, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.2857, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.0810, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.6509, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.6984, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.0041, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.9499, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.0104, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(3.0544, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.1156, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.8802, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.2154, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.8312, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.6403, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.1034, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.6308, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.9577, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.2464, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.4954, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.5907, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.1509, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.4451, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.2900, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.7422, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.1387, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.9014, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(3.1235, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.5347, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.0141, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.9205, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.7237, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.9213, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.1502, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.8325, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.9589, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.8136, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.4461, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.8475, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.4016, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.3089, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.8175, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.5806, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.6105, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.1848, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.1134, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.0825, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.2805, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.1222, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.0372, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(3.0154, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.6097, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.3242, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.1044, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(0.9650, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.6088, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.4550, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.1975, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.7002, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.1278, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.8088, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.4646, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.0444, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.5871, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.6588, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.7133, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.9671, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.9139, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.7213, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.5554, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.5023, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.0489, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(0.7337, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.4716, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.4303, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.6840, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.6986, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(0.9993, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.3774, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.6004, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.7264, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.2733, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.5745, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.0229, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.1420, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(0.9638, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.6509, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.8607, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.5396, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(3.3600, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.7287, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.3413, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.6155, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.6040, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.1448, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.3845, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.2712, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.3891, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.0375, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(4.5132, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.0216, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.6491, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.6963, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.0655, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.4247, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.2899, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.0144, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.0521, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.8809, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.4644, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.5206, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.5918, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.5979, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.9847, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.7949, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(4.4203, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.1532, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.2533, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.3917, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.1035, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.7194, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.2801, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.8283, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(3.2260, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.4599, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.8327, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.8699, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.1151, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.9669, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.0306, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.0452, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.8869, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.5683, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.2896, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.4479, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.2792, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.8077, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(3.1435, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.3927, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.8224, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.5764, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.9468, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.4300, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.8770, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.1514, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.4390, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.3600, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.4960, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.9180, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.8231, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.1555, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.8404, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.5466, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.4484, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.3233, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.8152, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.0255, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(3.3815, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.8478, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.5452, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.7917, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.3424, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.4662, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(3.1491, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(3.6284, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.3304, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.9041, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.4943, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.5150, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.8239, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.5387, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.1347, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.9550, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.0068, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.8708, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.5794, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.4108, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.0919, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.5672, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.6385, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.2424, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.6338, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.6093, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.4150, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.6818, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.7807, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(0.7222, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.2038, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.5322, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.7904, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.2522, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.8104, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.5311, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.0951, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.2578, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.0998, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.0901, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.3573, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.0489, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.2217, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.3866, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.4841, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.4310, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.3237, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.9022, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.3551, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.2178, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.4418, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.5279, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.8971, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.4889, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.8395, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.5668, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.5034, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(3.1182, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.2530, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.4786, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.9953, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.4593, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.2765, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.2854, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.4189, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.0839, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.3389, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.1886, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.8862, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.4365, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.5677, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.5002, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.7757, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.0068, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.2972, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.2535, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.3676, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(3.4678, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.3512, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.3897, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.6273, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.4366, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.2571, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.3593, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(0.9385, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.4813, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.1774, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.4279, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.7976, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.8143, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.2689, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.5313, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(0.9166, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.4767, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.9701, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.3807, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.1188, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.5869, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.6192, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.3525, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.1800, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.7982, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(3.3941, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.9182, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.8667, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.6172, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.7250, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.7380, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.5075, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.6375, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.5059, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.0272, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(0.6919, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.7368, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.5210, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.3843, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.1510, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.7362, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.4548, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.6428, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.5529, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.5012, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.4767, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.6750, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.4301, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.4847, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.2583, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.8839, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.3409, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.0538, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.6806, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.7633, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.5087, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.0010, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.9993, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.5823, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.8588, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.8941, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.6065, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.0162, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.2043, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(3.5866, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.6315, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.9552, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.8746, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.6751, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.5386, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.4967, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(0.9390, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.0895, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.9066, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.9328, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.7327, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(4.8513, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.3911, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(6.3680, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.3832, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.5016, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.3666, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.4994, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(0.6925, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.0557, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.4861, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.3744, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.7537, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.7434, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.4499, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.4045, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.4241, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.8323, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.0417, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.0596, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.1855, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.7775, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.7180, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(4.8789, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.4574, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.2409, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(0.8155, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.1145, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.1998, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(0.5983, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.6899, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.3307, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.7627, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.6656, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.1169, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.7257, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.9644, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.8068, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.8904, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.4037, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.9453, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.0037, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.2330, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.8380, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.3761, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.7850, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.3127, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.3434, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.1047, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.6222, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.6938, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(3.2008, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.5658, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.6938, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.0053, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.1689, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.6107, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.2805, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.2081, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.2015, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(3.3865, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.4053, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.5719, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.8205, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.2591, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.8022, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.1214, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.7434, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.2223, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.4712, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.4746, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.5258, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.5479, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.3507, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.1790, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.8604, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.5482, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.9514, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(3.0078, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.4484, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.8527, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.0300, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.0692, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.4548, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.3144, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.4575, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.3633, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.1820, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.0959, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.6062, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.7267, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.1019, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(3.4705, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.5220, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.6769, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(3.0503, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(3.1463, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.6699, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.9501, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.8044, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.9185, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.5510, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.3750, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(4.3362, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.3417, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.7797, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.2261, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.3668, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.4416, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.6073, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.1746, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.8022, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.4609, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.6003, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.7101, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.1110, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.8067, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.7450, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.0981, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.6348, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(0.8393, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.6014, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.7236, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.8279, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.6800, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.1558, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(0.4458, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.3790, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.0430, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.7692, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.9695, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.7560, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.9159, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.4327, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.8520, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.5334, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(3.2518, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.6730, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.4862, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.1110, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(3.1518, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.7027, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.4801, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(3.2894, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.6847, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.0881, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.9043, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.9746, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.4811, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.2992, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.2831, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.7778, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.2668, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.3067, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.0347, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.2644, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.2037, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.6446, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.0893, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.2713, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.2439, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.4661, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.4014, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.0000, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.7912, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.2298, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.3361, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.5872, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.7503, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.0670, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.6491, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.0712, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(3.9784, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.2398, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.2250, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.2348, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.0147, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "print_every = 5\n",
    "for epoch in range(epochs):\n",
    "    for inputs, labels in train_dataloader:\n",
    "        steps += 1\n",
    "        # Move input and label tensors to the default device\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logps = model.forward(inputs)\n",
    "        loss = criterion(logps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        print(\"Epoch: \", epoch, \"     Loss: \", loss)\n",
    "        \n",
    "        '''if steps % print_every == 0:\n",
    "            test_loss = 0\n",
    "            accuracy = 0\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in test_dataloader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    logps = model.forward(inputs)\n",
    "                    batch_loss = criterion(logps, labels)\n",
    "                    \n",
    "                    test_loss += batch_loss.item()\n",
    "                    \n",
    "                    # Calculate accuracy\n",
    "                    ps = torch.exp(logps)\n",
    "                    top_p, top_class = ps.topk(1, dim=1)\n",
    "                    equals = top_class == labels.view(*top_class.shape)\n",
    "                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "                    \n",
    "            print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
    "                  f\"Train loss: {running_loss/print_every:.3f}.. \"\n",
    "                  f\"Test loss: {test_loss/len(test_dataloader):.3f}.. \"\n",
    "                  f\"Test accuracy: {accuracy/len(test_dataloader):.3f}\")\n",
    "            running_loss = 0\n",
    "            model.train()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing your network\n",
    "\n",
    "It's good practice to test your trained network on test data, images the network has never seen either in training or validation. This will give you a good estimate for the model's performance on completely new images. Run the test images through the network and measure the accuracy, the same way you did validation. You should be able to reach around 70% accuracy on the test set if the model has been trained well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Testing...\n",
      "Epoch:  1/3..  Train Loss: 1.858..  Test Loss: 0.930..  Test Accuracy: 0.769\n",
      "Training...\n",
      "Testing...\n",
      "Epoch:  2/3..  Train Loss: 1.958..  Test Loss: 1.109..  Test Accuracy: 0.746\n",
      "Training...\n",
      "Testing...\n",
      "Epoch:  3/3..  Train Loss: 1.857..  Test Loss: 1.153..  Test Accuracy: 0.717\n"
     ]
    }
   ],
   "source": [
    "# TODO: Do validation on the test set\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_losses, test_losses = [], []\n",
    "epochs = 3\n",
    "steps = 0\n",
    "\n",
    "\n",
    "# Turn off gradients for validation, saves memory and computations\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    print(\"Training...\")\n",
    "    for images, labels in train_dataloader:\n",
    "        steps += 1\n",
    "        # Move input and label tensors to the default device\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logps = model.forward(images)\n",
    "        loss = criterion(logps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        test_loss = 0\n",
    "        accuracy = 0\n",
    "        print(\"Testing...\")\n",
    "        ## TODO: Implement the validation pass and print out the validation accuracy\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for images, labels in valid_dataloader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                log_ps = model.forward(images)\n",
    "                test_loss += criterion(log_ps, labels)\n",
    "                ps = torch.exp(log_ps)\n",
    "                top_p, top_class = ps.topk(1, dim=1)\n",
    "                equals = top_class == labels.view(*top_class.shape)\n",
    "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "        model.train()\n",
    "        train_losses.append(running_loss/len(train_dataloader))\n",
    "        test_losses.append(test_loss/len(valid_dataloader))\n",
    "        print(\"Epoch:  {}/{}.. \".format(e+1, epochs),\n",
    "              \"Train Loss: {:.3f}.. \".format(running_loss/len(train_dataloader)),\n",
    "              \"Test Loss: {:.3f}.. \".format(test_loss/len(valid_dataloader)),\n",
    "              \"Test Accuracy: {:.3f}\".format(accuracy/len(valid_dataloader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the checkpoint\n",
    "\n",
    "Now that your network is trained, save the model so you can load it later for making predictions. You probably want to save other things such as the mapping of classes to indices which you get from one of the image datasets: `image_datasets['train'].class_to_idx`. You can attach this to the model as an attribute which makes inference easier later on.\n",
    "\n",
    "```model.class_to_idx = image_datasets['train'].class_to_idx```\n",
    "\n",
    "Remember that you'll want to completely rebuild the model later so you can use it for inference. Make sure to include any information you need in the checkpoint. If you want to load the model and keep training, you'll want to save the number of epochs as well as the optimizer state, `optimizer.state_dict`. You'll likely want to use this trained model in the next part of the project, so best to save it now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Save the checkpoint \n",
    "checkpoint = {'input_size': 25088,\n",
    "              'output_size': 102,\n",
    "              'epochs': 2,\n",
    "              'state_dict': model.state_dict(),\n",
    "              'optimizer': optimizer.state_dict()}\n",
    "\n",
    "torch.save(checkpoint, 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the checkpoint\n",
    "\n",
    "At this point it's good to write a function that can load a checkpoint and rebuild the model. That way you can come back to this project and keep working on it without having to retrain the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU(inplace)\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace)\n",
      "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace)\n",
      "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (12): ReLU(inplace)\n",
      "    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (14): ReLU(inplace)\n",
      "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (17): ReLU(inplace)\n",
      "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (19): ReLU(inplace)\n",
      "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=2048, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2)\n",
      "    (3): Linear(in_features=2048, out_features=512, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.2)\n",
      "    (6): Linear(in_features=512, out_features=102, bias=True)\n",
      "    (7): LogSoftmax()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# TODO: Write a function that loads a checkpoint and rebuilds the model\n",
    "def load_checkpoint(filepath):\n",
    "    checkpoint = torch.load(filepath)\n",
    "    classifier = nn.Sequential(nn.Linear(25088, 2048),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(0.2),\n",
    "                                 nn.Linear(2048, 512),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(0.2),\n",
    "                                 nn.Linear(512, 102),\n",
    "                                 nn.LogSoftmax(dim=1))\n",
    "    model = models.vgg11(pretrained=True)\n",
    "    model.classifier = classifier\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    return model\n",
    "model = load_checkpoint('checkpoint.pth')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference for classification\n",
    "\n",
    "Now you'll write a function to use a trained network for inference. That is, you'll pass an image into the network and predict the class of the flower in the image. Write a function called `predict` that takes an image and a model, then returns the top $K$ most likely classes along with the probabilities. It should look like \n",
    "\n",
    "```python\n",
    "probs, classes = predict(image_path, model)\n",
    "print(probs)\n",
    "print(classes)\n",
    "> [ 0.01558163  0.01541934  0.01452626  0.01443549  0.01407339]\n",
    "> ['70', '3', '45', '62', '55']\n",
    "```\n",
    "\n",
    "First you'll need to handle processing the input image such that it can be used in your network. \n",
    "\n",
    "## Image Preprocessing\n",
    "\n",
    "You'll want to use `PIL` to load the image ([documentation](https://pillow.readthedocs.io/en/latest/reference/Image.html)). It's best to write a function that preprocesses the image so it can be used as input for the model. This function should process the images in the same manner used for training. \n",
    "\n",
    "First, resize the images where the shortest side is 256 pixels, keeping the aspect ratio. This can be done with the [`thumbnail`](http://pillow.readthedocs.io/en/3.1.x/reference/Image.html#PIL.Image.Image.thumbnail) or [`resize`](http://pillow.readthedocs.io/en/3.1.x/reference/Image.html#PIL.Image.Image.thumbnail) methods. Then you'll need to crop out the center 224x224 portion of the image.\n",
    "\n",
    "Color channels of images are typically encoded as integers 0-255, but the model expected floats 0-1. You'll need to convert the values. It's easiest with a Numpy array, which you can get from a PIL image like so `np_image = np.array(pil_image)`.\n",
    "\n",
    "As before, the network expects the images to be normalized in a specific way. For the means, it's `[0.485, 0.456, 0.406]` and for the standard deviations `[0.229, 0.224, 0.225]`. You'll want to subtract the means from each color channel, then divide by the standard deviation. \n",
    "\n",
    "And finally, PyTorch expects the color channel to be the first dimension but it's the third dimension in the PIL image and Numpy array. You can reorder dimensions using [`ndarray.transpose`](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.ndarray.transpose.html). The color channel needs to be first and retain the order of the other two dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    ''' Scales, crops, and normalizes a PIL image for a PyTorch model,\n",
    "        returns an Numpy array\n",
    "    '''\n",
    "    # TODO: Process a PIL image for use in a PyTorch model\n",
    "    e1 = image.size[0]\n",
    "    e2 = image.size[1]\n",
    "    if e1 < e2:\n",
    "        h = int(256/e1 * e2)\n",
    "        image = image.resize((256, h))\n",
    "        m = int((h-224)/2)\n",
    "        image = image.crop((16,m,16+224,m+224))\n",
    "    else:\n",
    "        w = int(256/e2 * e1)\n",
    "        image = image.resize((w, 256))\n",
    "        m = int((w-224)/2)\n",
    "        image = image.crop((m,16,m+224,16+224))\n",
    "    np_image = np.array(image)\n",
    "    np_image = np.true_divide(np_image, 255)\n",
    "    np_image -= [0.485, 0.456, 0.406]\n",
    "    np_image /= [0.229, 0.224, 0.225]\n",
    "    np_image = np_image.transpose((2,0,1))\n",
    "    img = torch.FloatTensor([np_image])\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check your work, the function below converts a PyTorch tensor and displays it in the notebook. If your `process_image` function works, running the output through this function should return the original image (except for the cropped out portions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(image, ax=None, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    \n",
    "    # PyTorch tensors assume the color channel is the first dimension\n",
    "    # but matplotlib assumes is the third dimension\n",
    "    image = image.view(image.size()[0]*image.size()[1], image.size()[2], image.size()[3])\n",
    "    image = image.numpy()\n",
    "    image = image.transpose((1, 2, 0))\n",
    "    print(image.shape)\n",
    "    # Undo preprocessing\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    image = std * image + mean\n",
    "    \n",
    "    # Image needs to be clipped between 0 and 1 or it looks like noise when displayed\n",
    "    image = np.clip(image, 0, 1)\n",
    "    \n",
    "    ax.imshow(image)\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Prediction\n",
    "\n",
    "Once you can get images in the correct format, it's time to write a function for making predictions with your model. A common practice is to predict the top 5 or so (usually called top-$K$) most probable classes. You'll want to calculate the class probabilities then find the $K$ largest values.\n",
    "\n",
    "To get the top $K$ largest values in a tensor use [`x.topk(k)`](http://pytorch.org/docs/master/torch.html#torch.topk). This method returns both the highest `k` probabilities and the indices of those probabilities corresponding to the classes. You need to convert from these indices to the actual class labels using `class_to_idx` which hopefully you added to the model or from an `ImageFolder` you used to load the data ([see here](#Save-the-checkpoint)). Make sure to invert the dictionary so you get a mapping from index to class as well.\n",
    "\n",
    "Again, this method should take a path to an image and a model checkpoint, then return the probabilities and classes.\n",
    "\n",
    "```python\n",
    "probs, classes = predict(image_path, model)\n",
    "print(probs)\n",
    "print(classes)\n",
    "> [ 0.01558163  0.01541934  0.01452626  0.01443549  0.01407339]\n",
    "> ['70', '3', '45', '62', '55']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_path, model, topk=5):\n",
    "    ''' Predict the class (or classes) of an image using a trained deep learning model.\n",
    "    '''\n",
    "    img = Image.open(image_path)\n",
    "    img = process_image(img)\n",
    "    \n",
    "    log_ps = model(img)\n",
    "    ps = torch.exp(log_ps)\n",
    "    probs, classIdxes = ps.topk(topk, dim=1)\n",
    "    model.class_to_idx = train_data.class_to_idx\n",
    "    \n",
    "    idx_to_class = {value : key for key,value in model.class_to_idx.items()}\n",
    "    \n",
    "    classes = []\n",
    "    for n in classIdxes[0]:\n",
    "        classes.append(cat_to_name[idx_to_class[int(n)]])\n",
    "    #imshow(img)\n",
    "    probs = probs.detach().numpy()[0]\n",
    "    print(\"Numpy probs: \", probs)\n",
    "    plt.subplot(2, 1, 1) # 1 row, 2 cols, subplot 1\n",
    "    imshow(img, ax=plt.subplot(2,1,1))\n",
    "    plt.subplot(2, 1, 2) # 1 row, 2 cols, subplot 2\n",
    "    plt.bar(classes, probs)\n",
    "    plt.xlabel(\"flower types\")\n",
    "    plt.ylabel(\"probability\")\n",
    "    plt.xticks(rotation = 45)\n",
    "    \n",
    "    #return {\"probs\" : probs, \"classes\": classes}\n",
    "    # TODO: Implement the code to predict the class from an image file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Checking\n",
    "\n",
    "Now that you can use a trained model for predictions, check to make sure it makes sense. Even if the testing accuracy is high, it's always good to check that there aren't obvious bugs. Use `matplotlib` to plot the probabilities for the top 5 classes as a bar graph, along with the input image. It should look like this:\n",
    "\n",
    "<img src='assets/inference_example.png' width=300px>\n",
    "\n",
    "You can convert from the class integer encoding to actual flower names with the `cat_to_name.json` file (should have been loaded earlier in the notebook). To show a PyTorch tensor as an image, use the `imshow` function defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy probs:  [  9.80295062e-01   1.80214774e-02   1.31575251e-03   1.58652911e-04\n",
      "   6.63480023e-05]\n",
      "(224, 224, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/matplotlib/cbook/deprecation.py:106: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f61ed16c2e8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Display an image along with the top 5 classes\n",
    "img_path = \"flowers/test/21/image_06807.jpg\"\n",
    "predict(img_path, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
